# Constructions-Are-So-Difficult

## Experimental Setup
### prompting

We only accept output with exact one label "Entailment" or "Contraction" as a valid answer, and keep regenerating until it returns a valid one.

a) GPT-3.5 & GPT-4
OpenAI API: "gpt-3.5-turbo", "gpt-4-0613"
All with default hyperparameters:
frequency_penalty=0, presence_penalty=0, temperature=1, top_p=1, max_tokens=null


b) Llama 2
Huggingface: "meta-llama/Llama-2-70b-chat-hf"
model.eval()
SamplingParams(temperature=0.7, top_p=0.95, top_k=40, max_tokens=512)


### probing classifier
we extract the last-layer embeddings generated by LLMs and then apply perceptron-based classification to these embeddings, to assess how well the categories(CEC, OCE, EAP and AAP) are internally represented in the models. All experiments repeated 5 rounds.

a) GPT
OpenAI API: "text-embedding-ada-002"
the last-layer embeddings of sentences

b) Llama 2
the last-layer embeddings of sentences and of the adjectives, which license the so that construction.
